# LLM Behavior & Agent Engineering Roadmap

This repository documents a structured, hands-on learning journey into **LLM behavior, prompt engineering, and agentic workflow design**, progressing from foundational model experiments to a deterministic function-calling assistant with guardrails and retry logic.

The goal of this project is to deeply understand:

- How LLMs work internally
- How prompting affects behavior
- How to build agents from scratch
- How to design guardrails and reliability
- How to control cost and determinism

This is framework-independent agent engineering.

---

# ğŸ“ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ week1/
â”‚   â”œâ”€â”€ temperature_experiment.py
â”‚   â”œâ”€â”€ token_experiment.py
â”‚   â”œâ”€â”€ json_experiment.py
â”‚   â”œâ”€â”€ fewshot_experiment.py
â”‚   â””â”€â”€ prompt_debugging.py
â”‚
â”œâ”€â”€ week2/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ agent.py
â”‚   â””â”€â”€ tools/
â”‚
â”œâ”€â”€ week3/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ assistant.py
â”‚   â”œâ”€â”€ schemas.py
â”‚   â””â”€â”€ tools/
â”‚
â””â”€â”€ README_FULL_AGENTIC_ROADMAP.md
```

---

# âš™ï¸ Environment Setup

## 1ï¸âƒ£ Create Virtual Environment

### Mac/Linux
```bash
python -m venv .venv
source .venv/bin/activate
```

### Windows
```bash
python -m venv .venv
.venv\Scripts#ctivate
```

---

## 2ï¸âƒ£ Install Dependencies

```bash
pip install openai python-dotenv
```

(Optional: use `requirements.txt` if available.)

---

# ğŸ” .env Configuration (Required)

Create a `.env` file at the **root of the project**.

```text
project-root/
â”œâ”€â”€ .env   â† MUST be here
```

### Sample `.env`

```text
OPENAI_API_KEY=your_api_key_here
MODEL=gpt-4.1-mini
```

âš ï¸ Important:
- Do NOT commit your real API key
- Add `.env` to `.gitignore`
- API keys must remain local

---

# ğŸ§  Week 1 â€” LLM + OpenAI API Foundation

## Concepts Learned

### 1ï¸âƒ£ Tokens
- LLM reads tokens, not words
- Cost depends on tokens
- Context depends on tokens
- Long prompts increase cost and latency

### 2ï¸âƒ£ Context Window
- Max tokens model can process in one request
- Prompt + response must fit in window
- Long conversations cause truncation
- Leads to need for RAG

### 3ï¸âƒ£ Temperature
- Controls randomness
- 0 â†’ deterministic
- 0.7 â†’ balanced
- 1 â†’ creative / unstable

### 4ï¸âƒ£ Top-p
- Controls probability sampling range
- Typically left default

### 5ï¸âƒ£ Max Tokens
- Limits output length
- Controls cost

### 6ï¸âƒ£ System vs User Messages
- System â†’ behavior control
- User â†’ task input

### 7ï¸âƒ£ Cost Concept
- Cost = input tokens + output tokens
- Prompt design directly affects cost

---

## ğŸ§ª Experiments Conducted

### Experiment 1 â€” Temperature Impact
Prompt: â€œExplain Python in 2 linesâ€
- Run with temperature = 0
- Run with temperature = 1
Observed:
- Determinism vs creativity
- Repetition vs variation

---

### Experiment 2 â€” Token Size Impact
- Short prompt
- Long prompt
Observed:
- Response quality
- Latency difference
- Token usage difference

---

### Experiment 3 â€” Force JSON Output
Prompt: â€œReturn ONLY valid JSON: {"summary": string}â€
Tested:
- With structure instruction
- Without structure instruction
Observed:
- Hallucination
- Format reliability

---

### Experiment 4 â€” Few-shot vs Zero-shot
Task: Sentiment classification
- Without examples
- With 3 examples
Observed:
- Accuracy differences
- Output structure variation

---

### Experiment 5 â€” Prompt Debugging
- Gave ambiguous prompt
- Improved with:
  - Role
  - Constraints
  - Structure
Observed improvement.

---

## ğŸ¯ Week 1 Deliverable

CLI Smart Chatbot:
- Structured output
- Logging
- Retry handling

---

# ğŸ¤– Week 2 â€” ReAct Agent (Reason â†’ Act â†’ Observe)

## Concepts Learned

- Agent loop
- Tool usage
- Execution cycles
- Failure modes
- Why string parsing is fragile

---

## Tools Built

- Calculator
- Web Search (mocked)
- File Reader

---

## Architecture

User  
â†“  
Agent  
â†“  
Reason  
â†“  
Select Tool  
â†“  
Execute Tool  
â†“  
Observe  
â†“  
Respond  

---

## Key Learnings

- String-based action parsing is unstable
- Infinite loops possible
- No schema validation
- No deterministic guardrails
- Need structured tool calling

---

## Week 2 Deliverable

Tool-Using Agent:
- User asks question
- Agent selects tool
- Tool executes
- Agent responds

---

# ğŸ›  Week 3 â€” Function Calling + Structured Tools

## Concepts Learned

- Function calling
- JSON Schema
- Guardrails
- Deterministic execution
- Retry logic
- Tool whitelist enforcement
- Parallel tool control

---

## Tools Built

- Email Summarizer
- JSON Extractor
- Task Planner

---

## Architecture

User  
â†“  
LLM (Function Calling)  
â†“  
Schema Validation  
â†“  
Execution Layer  
â†“  
Guardrails  
â†“  
Structured Response  

---

## Guardrails Implemented

- Single tool call enforcement
- Disabled parallel tool calls
- Tool whitelist validation
- JSON argument validation
- Retry on malformed model output
- Structured response format
- Deterministic behavior (temperature=0)
- Token usage tracking
- Error handling

---

## Example Output

```json
{
  "status": "success",
  "tool": "json_extractor",
  "data": {
    "order_id": "123",
    "amount": "50",
    "status": "Shipped"
  }
}
```

---

## Week 3 Deliverable

Personal Assistant Agent (v1)

---


Questions:

- What is a token?
- Why token size affects cost?
- Temperature vs top-p?
- What is context window?
- Why model forgets long conversations?
- How to reduce hallucination?
- How to force JSON output?
- What happens internally when calling LLM API?
- What is few-shot prompting?

---

# ğŸ“š Important Learning Resources

Core LLM + OpenAI
- OpenAI Quickstart  
- Responses API  
- Function Calling  
- Embeddings  
- Evals  

Prompt Engineering
- DeepLearning.AI Prompt Engineering Course  

Agents + RAG
- LangChain Docs  
- LangGraph Tutorials  
- RAG Guide  

Multi-Agent Systems
- CrewAI Docs  
- Microsoft AutoGen  

Vector Databases
- FAISS  

Backend + Automation
- FastAPI  
- Playwright Python  

Observability
- LangSmith  

---

# ğŸ”’ Security Notice

- No API keys stored in repository
- `.env` required locally
- Secrets excluded from version control
- Personal API key not checked in

---
